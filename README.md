
# Comparison of Multiple Generators in GANs and Analysis of Generated Datasets


**_Abstract -_** In this paper, we propose a new approach to train Generative Adversarial Nets (GANs) using a custom mixture of generators to address the mode collapsing problem. Instead of a single generator, we employ multiple generators, effectively covering diverse data modes and overcoming mode collapse. Our method uses a minimax formulation among a classifier, a discriminator, and a set of generators. Generators create samples from the training data distribution, the discriminator distinguishes between real and generated samples, and the classifier identifies the generator of each sample. Internal samples are created by multiple generators, with one randomly selected as the final output, akin to a probabilistic mixture model. We introduce a custom training loop in our Mixture Generative Adversarial Nets (MGAN) and provide theoretical analysis on generator configurations. Extensive experiments on synthetic 2D breast cancer cell data demonstrate that our MGAN achieves state-of-the-art Inception scores, generating diverse and recognizable objects at various resolutions, and effectively capturing different object types


## Authors

- [Abdul Rahman Shigihalli](https://www.github.com/abdul-bit)
- [Akash Mehta]([https://github.com/aanchal-n](https://www.linkedin.com/in/kash666/))
- [Suhas K Pai]([https://github.com/naren951](https://www.linkedin.com/in/k-suhas-pai/))



## Proposed Evaluations

Our main contributions to this project are: 
- A custom training loop for the adversarial model to efficiently train a mixture of generator.
- A comprehensive evaluation on the performance of our method on generating real world-scale datasets of diverse cancer cells by using a separate classifier.

The images after being generated by the different sets of
Gan’s will then be formatted into a dataset and further tested
on a separate classifier to confirm which set will yield the
most accurate results.


## Dataset

The Breast cancer dataset from breakhis has been used in
this paper. The dataset contains a training set and a testing
set each containing subdivisions of different levels of
magnifications of the cells, for eg. 40X, 100X etc. For
efficiency and time related issues, we chose to make use of
the 40X magnification folder for both training and testing.
The data needed to be cleaned and pickled into a numpy
array to be fed into the MGAN. Within the chosen
magnification lies sub-labels for benign and malignant
samples. Hence two pickle files need to be created to train
the model separately. Due to the target images being detailed
cells, the necessity of high accuracy and precision needed to
be met, hence the data was appropriately segregated and
chosen for training and testing purposes. To replicate an
original dataset after all, takes quite a lot of effort to make
sure almost no visible difference remains between the faux
and original.

## Working of the MGAN
The idea here is to use a mixture of many distributions
rather than a single one as in the standard GAN, to
approximate the data distribution. Simultaneously we
enlarge the divergence of those distributions so that they
cover different data modes.
Taking an analogy to a game among K generators G1:K,
a discriminator D and a classifier C can be formulated.
Each generator Gk maps z to x = Gk (z), thus inducing a
single distribution PGk ; and K generators altogether
induce a mixture over K distributions, namely
P model in the data space. An index u is drawn from a
multinomial distribution Mult(π), where π = [π1, π2, ...,
πK] is the coefficients of the mixture; and then the
sample Gu (z) is used as the output. Here, we use a
predefined π and fix it instead of learning. The
discriminator D aims to distinguish between this sample
and the training samples. The classifier C performs
multi-class classification to classify samples labeled by
the indices of their corresponding generators. We term
this whole process and our model the Mixture
Generative Adversarial Nets (MGAN).

##  Dataset Generation
The basic intuition here is to generate multiple unique
data samples for our model, as well as minimizing the
problem of modal collapse. We reused the experimental
design proposed in (Metz et al., 2016) to investigate how
well our MGAN can explore and capture multiple data
modes. The training data is sampled from a 2D mixture
of 8 isotropic Gaussian distributions with a covariance
matrix of 0.02I and means arranged in a circle of zero
centroid and radius of 2.0. Our purpose of using such
small variance is to create low density regions and
separate the modes. We employ 4 generators, each with a
simple architecture of an input layer with 256 noise units
drawn from isotropic multivariate Gaussian distribution
N (0, I), and two fully connected hidden layers with 128
ReLU units each. For the discriminator and classifier,
one hidden layer with 128 ReLU units is used. The
diversity hyperparameter β is set to 0.125.

## Evaluation
We present samples randomly generated by our proposed
model trained on the 2 datasets (one benign and one
malignant) for qualitative assessment. Our dataset
contains a wide range benign and malignant colored
microscopic images consisting of training dataset and a
testing dataset each containing subdivisions of different
levels of magnifications of the cells such as 40X, 100X
etc. Images generated from our custom dataset each with
a resolution 64×64, are diverse with some recognizable
objects pink hue, cancer generated mass and our the
MGAN is capable of generating visually appealing
images with complicated details. However, many
samples are still incomplete and unrealistic which can be
inferred from closer inspection of the dataset generated

## Experimental Results


![image](https://github.com/abdul-bit/Colorisation-of-Black-and-White-Images/assets/59999587/077a75e3-bb57-4fc2-869d-4677cab8f595)

![image](https://github.com/abdul-bit/Colorisation-of-Black-and-White-Images/assets/59999587/ce64364e-6d8c-4070-8b2d-8b4ddf099ed1)

![image](https://github.com/abdul-bit/Colorisation-of-Black-and-White-Images/assets/59999587/ba280c97-190d-4f67-b49b-1dd4129223b1)



## References

- **Quan Hoang, Tu Dinh Nguyen, Trung Le, Dinh Phung.**
 _"MGAN: Training Generative Adversarial Nets with Multiple Generators"._ International Conference on Learning Representations.
-  **Ian J. Goodfellow, Jean Pouget-Abadie , Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair , Aaron Courville, Yoshua Bengio.**
Generative Adversarial Nets(GAN)
-  **Ken’ich Morooka1 , Xueru Zhang1 , Shoko Miyauchi, Kyushu University, Fukuoka**
 GAN-based Method for Synthesizing Multi-Focus Cell Images.
-  **I. S. Jacobs and C. P. Bean**
 _“Fine particles, thin films and exchange
anisotropy,”_ in Magnetism, vol. III, G. T. Rado and H. Suhl, Eds. New
York: Academic, 1963, pp. 271–350.
- **Ishan Durugkar, Ian Gemp, Sridhar Mahadevan**
 _"Generative Multi-Adversarial Networks."_ ICLR 2017 conference 05 Nov 2016.
- **Ken’ich Morooka1 , Xueru Zhang1 , Shoko Miyauchi, Kyushu University, Fukuoka.** 
GAN-based Method for Synthesizing
Multi-Focus Cell Images
